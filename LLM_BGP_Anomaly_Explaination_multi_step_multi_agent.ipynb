{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de592abb-4544-4ae5-ab29-386316841893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#read two dictionary of as paths to a certain IP prefix and ask LLM for BGP Event Report\n",
    "import pybgpstream\n",
    "import networkx as nx\n",
    "from itertools import groupby\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import collections\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import evaluate\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "openai.api_key = \"Your OPENAI API KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your OPENAI API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d8b758-161c-4ba9-a621-20c6f7a69330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Type</th>\n",
       "      <th>AS</th>\n",
       "      <th>AS2</th>\n",
       "      <th>IP</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>More info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>15169</td>\n",
       "      <td>174</td>\n",
       "      <td>64.233.161.0/24</td>\n",
       "      <td>2005-05-07 14:37:56</td>\n",
       "      <td>2005-05-09 10:52:00</td>\n",
       "      <td>Google Outage 2005</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>13414</td>\n",
       "      <td>8342</td>\n",
       "      <td>104.244.42.0/24</td>\n",
       "      <td>2022-03-28 12:05:00</td>\n",
       "      <td>2022-03-28 12:50:00</td>\n",
       "      <td></td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>36561</td>\n",
       "      <td>17557</td>\n",
       "      <td>208.65.153.0/24</td>\n",
       "      <td>2008-02-24 18:49:00</td>\n",
       "      <td>2008-02-24 21:01:00</td>\n",
       "      <td>YouTube Hijacking</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>7625</td>\n",
       "      <td>9457</td>\n",
       "      <td>211.249.216.0/21</td>\n",
       "      <td>2022-02-03 01:04:00</td>\n",
       "      <td>2022-02-03 01:09:00</td>\n",
       "      <td>KlaySwap Incident</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>8972</td>\n",
       "      <td>55410</td>\n",
       "      <td>5.35.230.0/24</td>\n",
       "      <td>2021-04-16 13:48:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Route Leak</td>\n",
       "      <td>22566</td>\n",
       "      <td>28548</td>\n",
       "      <td>201.157.49.0/24</td>\n",
       "      <td>2021-02-11 04:36:41</td>\n",
       "      <td>2021-02-11 04:48:21</td>\n",
       "      <td></td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>10990</td>\n",
       "      <td>812</td>\n",
       "      <td>99.225.224.0/19</td>\n",
       "      <td>2020-07-30 01:15:38</td>\n",
       "      <td>2020-07-30 01:19:49</td>\n",
       "      <td></td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Route Leak</td>\n",
       "      <td>1136</td>\n",
       "      <td>21217</td>\n",
       "      <td>46.145.0.0/16</td>\n",
       "      <td>2019-06-06 09:57:00</td>\n",
       "      <td>2019-06-06 11:00:00</td>\n",
       "      <td>Large European routing leak</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hijack</td>\n",
       "      <td></td>\n",
       "      <td>268869</td>\n",
       "      <td>101.101.101.0/24</td>\n",
       "      <td>2019-05-08 15:08:00</td>\n",
       "      <td>2019-05-08 15:11:42</td>\n",
       "      <td></td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Route Leak</td>\n",
       "      <td>20940</td>\n",
       "      <td>37468</td>\n",
       "      <td>2.16.0.0/13</td>\n",
       "      <td>2023-05-25 11:21:40</td>\n",
       "      <td>2023-05-25 12:41:36</td>\n",
       "      <td></td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>16509</td>\n",
       "      <td>10297</td>\n",
       "      <td>205.251.192.0/23</td>\n",
       "      <td>2018-04-24 11:05:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>2924</td>\n",
       "      <td>60916</td>\n",
       "      <td>64.233.161.0/24</td>\n",
       "      <td>2005-05-07 14:37:56</td>\n",
       "      <td>2005-05-09 10:52:00</td>\n",
       "      <td>Google Outage 2005</td>\n",
       "      <td>generate using event 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>72310</td>\n",
       "      <td>62038</td>\n",
       "      <td>104.244.42.0/24</td>\n",
       "      <td>2022-03-28 12:05:00</td>\n",
       "      <td>2022-03-28 12:50:00</td>\n",
       "      <td></td>\n",
       "      <td>generate using event 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>29049</td>\n",
       "      <td>62200</td>\n",
       "      <td>208.65.153.0/24</td>\n",
       "      <td>2008-02-24 18:49:00</td>\n",
       "      <td>2008-02-24 21:01:00</td>\n",
       "      <td>YouTube Hijacking</td>\n",
       "      <td>generate using event 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>74688</td>\n",
       "      <td>49438</td>\n",
       "      <td>211.249.216.0/21</td>\n",
       "      <td>2022-02-03 01:04:00</td>\n",
       "      <td>2022-02-03 01:09:00</td>\n",
       "      <td>KlaySwap Incident</td>\n",
       "      <td>generate using event 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>37068</td>\n",
       "      <td>9124</td>\n",
       "      <td>5.35.230.0/24</td>\n",
       "      <td>2021-04-16 13:48:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>generate using event 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Route Leak</td>\n",
       "      <td>75776</td>\n",
       "      <td>86364</td>\n",
       "      <td>201.157.49.0/24</td>\n",
       "      <td>2021-02-11 04:36:41</td>\n",
       "      <td>2021-02-11 04:48:21</td>\n",
       "      <td></td>\n",
       "      <td>generate using event 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>87706</td>\n",
       "      <td>9649</td>\n",
       "      <td>99.225.224.0/19</td>\n",
       "      <td>2020-07-30 01:15:38</td>\n",
       "      <td>2020-07-30 01:19:49</td>\n",
       "      <td></td>\n",
       "      <td>generate using event 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Route Leak</td>\n",
       "      <td>28382</td>\n",
       "      <td>71196</td>\n",
       "      <td>46.145.0.0/16</td>\n",
       "      <td>2019-06-06 09:57:00</td>\n",
       "      <td>2019-06-06 11:00:00</td>\n",
       "      <td>Large European routing leak</td>\n",
       "      <td>generate using event 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hijack</td>\n",
       "      <td></td>\n",
       "      <td>75191</td>\n",
       "      <td>101.101.101.0/24</td>\n",
       "      <td>2019-05-08 15:08:00</td>\n",
       "      <td>2019-05-08 15:11:42</td>\n",
       "      <td></td>\n",
       "      <td>generate using event 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Route Leak</td>\n",
       "      <td>9587</td>\n",
       "      <td>61009</td>\n",
       "      <td>2.16.0.0/13</td>\n",
       "      <td>2023-05-25 11:21:40</td>\n",
       "      <td>2023-05-25 12:41:36</td>\n",
       "      <td></td>\n",
       "      <td>generate using event 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hijack</td>\n",
       "      <td>29825</td>\n",
       "      <td>51929</td>\n",
       "      <td>205.251.192.0/23</td>\n",
       "      <td>2018-04-24 11:05:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>generate using event 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Event Type     AS     AS2                IP                Start  \\\n",
       "0       Hijack  15169     174   64.233.161.0/24  2005-05-07 14:37:56   \n",
       "1       Hijack  13414    8342   104.244.42.0/24  2022-03-28 12:05:00   \n",
       "2       Hijack  36561   17557   208.65.153.0/24  2008-02-24 18:49:00   \n",
       "3       Hijack   7625    9457  211.249.216.0/21  2022-02-03 01:04:00   \n",
       "4       Hijack   8972   55410     5.35.230.0/24  2021-04-16 13:48:00   \n",
       "5   Route Leak  22566   28548   201.157.49.0/24  2021-02-11 04:36:41   \n",
       "6       Hijack  10990     812   99.225.224.0/19  2020-07-30 01:15:38   \n",
       "7   Route Leak   1136   21217     46.145.0.0/16  2019-06-06 09:57:00   \n",
       "8       Hijack         268869  101.101.101.0/24  2019-05-08 15:08:00   \n",
       "9   Route Leak  20940   37468       2.16.0.0/13  2023-05-25 11:21:40   \n",
       "10      Hijack  16509   10297  205.251.192.0/23  2018-04-24 11:05:00   \n",
       "11      Hijack   2924   60916   64.233.161.0/24  2005-05-07 14:37:56   \n",
       "12      Hijack  72310   62038   104.244.42.0/24  2022-03-28 12:05:00   \n",
       "13      Hijack  29049   62200   208.65.153.0/24  2008-02-24 18:49:00   \n",
       "14      Hijack  74688   49438  211.249.216.0/21  2022-02-03 01:04:00   \n",
       "15      Hijack  37068    9124     5.35.230.0/24  2021-04-16 13:48:00   \n",
       "16  Route Leak  75776   86364   201.157.49.0/24  2021-02-11 04:36:41   \n",
       "17      Hijack  87706    9649   99.225.224.0/19  2020-07-30 01:15:38   \n",
       "18  Route Leak  28382   71196     46.145.0.0/16  2019-06-06 09:57:00   \n",
       "19      Hijack          75191  101.101.101.0/24  2019-05-08 15:08:00   \n",
       "20  Route Leak   9587   61009       2.16.0.0/13  2023-05-25 11:21:40   \n",
       "21      Hijack  29825   51929  205.251.192.0/23  2018-04-24 11:05:00   \n",
       "\n",
       "                    End                   Event Name                More info  \n",
       "0   2005-05-09 10:52:00           Google Outage 2005                     link  \n",
       "1   2022-03-28 12:50:00                                                  link  \n",
       "2   2008-02-24 21:01:00            YouTube Hijacking                     link  \n",
       "3   2022-02-03 01:09:00           KlaySwap Incident                      link  \n",
       "4                                                                        link  \n",
       "5   2021-02-11 04:48:21                                                  link  \n",
       "6   2020-07-30 01:19:49                                                  link  \n",
       "7   2019-06-06 11:00:00  Large European routing leak                     link  \n",
       "8   2019-05-08 15:11:42                                                  link  \n",
       "9   2023-05-25 12:41:36                                                  link  \n",
       "10                                                                       link  \n",
       "11  2005-05-09 10:52:00           Google Outage 2005   generate using event 0  \n",
       "12  2022-03-28 12:50:00                                generate using event 1  \n",
       "13  2008-02-24 21:01:00            YouTube Hijacking   generate using event 2  \n",
       "14  2022-02-03 01:09:00           KlaySwap Incident    generate using event 3  \n",
       "15                                                     generate using event 4  \n",
       "16  2021-02-11 04:48:21                                generate using event 5  \n",
       "17  2020-07-30 01:19:49                                generate using event 6  \n",
       "18  2019-06-06 11:00:00  Large European routing leak   generate using event 7  \n",
       "19  2019-05-08 15:11:42                                generate using event 8  \n",
       "20  2023-05-25 12:41:36                                generate using event 9  \n",
       "21                                                    generate using event 10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('Data/BGP_explain_data.csv', na_filter=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c823775e-b79a-4cc1-a70f-7d80a1a57609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGP_explaination():\n",
    "    '''\n",
    "    BGP event explaination object.\n",
    "    given detected time, IP/Target AS, extract AS paths from history routing table data, BGP messages before event, BGP messages after event\n",
    "    feed them to llm\n",
    "    '''\n",
    "    def __init__(self, collector_list, model = \"gpt-4o\", project = \"rcc\", save_path = \"e/\", read_path = None):\n",
    "        '''\n",
    "        initialize llm, collector_list, collector project\n",
    "        '''\n",
    "        self.llm = openai.OpenAI()\n",
    "        self.collector_list = collector_list\n",
    "        self.model = model\n",
    "        self.project = project\n",
    "        self.save_path = save_path #directory to save files\n",
    "        if not read_path:\n",
    "            read_path = save_path\n",
    "        self.read_path = read_path\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    def chat(self, messages, model, n=1):\n",
    "        '''\n",
    "        function to call llm api\n",
    "        '''\n",
    "        response = self.llm.chat.completions.create(\n",
    "                            model=model,\n",
    "                            messages=messages,\n",
    "                            n=n\n",
    "                            )\n",
    "        text_response = [response.choices[i].message.content for i in range(n)]\n",
    "        \n",
    "        return text_response\n",
    "\n",
    "    def generate_multi_event(self, data_path):\n",
    "        '''\n",
    "        generate report for each event recorded in data_path\n",
    "        '''\n",
    "        data = pd.read_csv(data_path, na_filter=False)\n",
    "        N = len(data)\n",
    "        for i in trange(N):\n",
    "            event = data.iloc[i]\n",
    "            start_time = event['Start'].split(';')[0] if event['Start'] else None\n",
    "            IP = event['IP'].split(';')[0] if event['IP'] else None\n",
    "            AS = event['AS'].split(';')[0] if event['AS'] else None\n",
    "            end_time = event['End'].split(';')[0] if event['End'] else None\n",
    "            event_type = event['Event Type'].split(';')[0] if event['Event Type'] else None\n",
    "            self.generate_single_event(start_time=start_time, file_save_prefix=str(i)+\"_\", IP=IP, AS=AS, end_time=end_time, Event_Type=event_type)\n",
    "        return None\n",
    "            \n",
    "    def generate_single_event(self, start_time, file_save_prefix=\"\", IP=None, AS=None, end_time=None, Event_Type=None):\n",
    "        '''\n",
    "        generate report for a single event\n",
    "        '''\n",
    "        if IP:\n",
    "            '''if IP is provided'''\n",
    "            #history_rib, rib_before_incident, rib_after_incident = self.AS_Path_IP(start_time=start_time, IP_prefix=IP, end_time = end_time)\n",
    "            with open(self.read_path + file_save_prefix + \"history_rib.json\", \"r\") as f:\n",
    "                history_rib = json.load(f)\n",
    "            with open(self.read_path + file_save_prefix + \"before_event_rib.json\", \"r\") as f:\n",
    "                rib_before_incident = json.load(f)\n",
    "            with open(self.read_path + file_save_prefix + \"after_event_rib.json\", \"r\") as f:\n",
    "                rib_after_incident = json.load(f)\n",
    "            try:\n",
    "                report, report_dict = self.generate_report(history_rib=history_rib,\n",
    "                                              rib_before_incident=rib_before_incident,\n",
    "                                              rib_after_incident=rib_after_incident,\n",
    "                                              time=start_time,\n",
    "                                              IP=IP,\n",
    "                                             Event_Type=Event_Type)\n",
    "            except:\n",
    "                return None\n",
    "            with open(self.save_path + file_save_prefix + \"report.txt\", \"w\") as f:\n",
    "                json.dump(report, f)\n",
    "            with open(self.save_path + file_save_prefix + \"reprot_dict.json\", \"w\") as f:\n",
    "                json.dump(report_dict, f)\n",
    "        elif AS:\n",
    "            '''IP not available but target AS available'''\n",
    "            history_rib, rib_before_incident, rib_after_incident = self.AS_Path_AS(start_time=start_time, target_AS=AS, end_time = end_time)\n",
    "            report = self.generate_report(history_rib=history_rib,\n",
    "                                          rib_before_incident=rib_before_incident,\n",
    "                                          rib_after_incident=rib_after_incident,\n",
    "                                          time=start_time,\n",
    "                                          AS=AS)\n",
    "        else:\n",
    "            raise(\"Must provide IP or AS\")\n",
    "        ###save routing table and report\n",
    "        # with open(self.save_path + file_save_prefix + \"history_rib.json\", \"w\") as f:\n",
    "        #     json.dump(history_rib, f)\n",
    "        # with open(self.save_path + file_save_prefix + \"before_event_rib.json\", \"w\") as f:\n",
    "        #     json.dump(rib_before_incident, f)\n",
    "        # with open(self.save_path + file_save_prefix + \"after_event_rib.json\", \"w\") as f:\n",
    "        #     json.dump(rib_after_incident, f)\n",
    "        \n",
    "            \n",
    "        return None\n",
    "\n",
    "    def AS_Path_IP(self, start_time, IP_prefix, end_time = None):\n",
    "        '''\n",
    "        provide target IP and time extract AS paths, end time is optional\n",
    "        '''\n",
    "        # convert start time to datetime object\n",
    "        start = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')\n",
    "        #convert end time to datetime object\n",
    "        if end_time: #if end time is provided\n",
    "            end = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')\n",
    "        else: #default 1 day after start\n",
    "            end = start + timedelta(days=1)\n",
    "\n",
    "\n",
    "        ###extract history routing table\n",
    "        history_rib = defaultdict(dict)\n",
    "        for collector in tqdm(self.collector_list):\n",
    "            #rcc collects rib every 8 hours, we pick the 2nd last checkpoint\n",
    "            stream = pybgpstream.BGPStream(\n",
    "                from_time=str(start-timedelta(hours=16)), until_time=str(start-timedelta(hours=8)),\n",
    "                collectors=[collector],\n",
    "                record_type=\"ribs\",\n",
    "                filter = f\"prefix any {IP_prefix}\"  #collect as path to ip prefix that are less or more specific to the target IP prefix\n",
    "            )\n",
    "            as_path = defaultdict(dict)\n",
    "\n",
    "            for rec in tqdm(stream.records()):\n",
    "                for ele in rec:\n",
    "                    # Get the peer ASn\n",
    "                    peer = str(ele.peer_asn)\n",
    "                    hops = [k for k, g in groupby(ele.fields['as-path'].split(\" \"))]\n",
    "                    #print(ele)\n",
    "                    if str(ele.type) == \"R\":\n",
    "                        if 'as-path' and \"prefix\" in ele.fields:\n",
    "                            IP = ele.fields[\"prefix\"]\n",
    "                            as_path[IP][peer] = hops\n",
    "            history_rib[collector] = as_path\n",
    "\n",
    "        ###extract AS-paths before event\n",
    "        rib_before_incident = copy.deepcopy(history_rib)\n",
    "        types = {\"A\", \"W\"}\n",
    "        for collector in tqdm(self.collector_list):\n",
    "            stream1 = pybgpstream.BGPStream(\n",
    "                from_time=str(start-timedelta(hours=8)), until_time=str(start-timedelta(minutes=10)),\n",
    "                collectors=[collector],\n",
    "                record_type=\"updates\",\n",
    "                filter = f\"prefix any {IP_prefix}\"\n",
    "            )\n",
    "            \n",
    "            for rec in tqdm(stream1.records()):\n",
    "                for elem in rec:\n",
    "                    if (str(elem.type) in types) and \"prefix\" in elem.fields:\n",
    "                        IP = str(elem.fields[\"prefix\"])\n",
    "                        if str(elem.type) == \"A\" and \"as-path\" in elem.fields:\n",
    "                            peer = str(elem.peer_asn)\n",
    "                            hops = [k for k, g in groupby(elem.fields['as-path'].split(\" \"))]\n",
    "                            rib_before_incident[collector][IP][peer] = hops\n",
    "                            \n",
    "                        if str(elem.type) == \"W\":\n",
    "                            peer = str(elem.peer_asn)\n",
    "                            rib_before_incident[collector][IP][peer] = []\n",
    "\n",
    "        ###extract AS-paths after event\n",
    "        rib_after_incident = copy.deepcopy(rib_before_incident)\n",
    "        #collect information until 1min before event end or 10min after event start\n",
    "        until = min(end-timedelta(minutes=1), start+timedelta(minutes=10))\n",
    "        for collector in tqdm(self.collector_list):\n",
    "            stream1 = pybgpstream.BGPStream(\n",
    "                from_time=str(start-timedelta(minutes=10)), until_time=str(until),\n",
    "                collectors=[collector],\n",
    "                record_type=\"updates\",\n",
    "                filter = f\"prefix any {IP_prefix}\"\n",
    "            )\n",
    "            \n",
    "            for rec in tqdm(stream1.records()):\n",
    "                for elem in rec:\n",
    "                    if (str(elem.type) in types) and \"prefix\" in elem.fields:\n",
    "                        IP = str(elem.fields[\"prefix\"])\n",
    "                        if str(elem.type) == \"A\" and \"as-path\" in elem.fields:\n",
    "                            peer = str(elem.peer_asn)\n",
    "                            hops = [k for k, g in groupby(elem.fields['as-path'].split(\" \"))]\n",
    "                            rib_after_incident[collector][IP][peer] = hops\n",
    "                            \n",
    "                        if str(elem.type) == \"W\":\n",
    "                            peer = str(elem.peer_asn)\n",
    "                            rib_after_incident[collector][IP][peer] = []\n",
    "\n",
    "        return history_rib, rib_before_incident, rib_after_incident\n",
    "\n",
    "    def AS_Path_AS(self, start_time, target_AS, end_time = None):\n",
    "        '''\n",
    "        Missing IP but provide target AS number and time to extract AS paths, end time is optional\n",
    "        '''\n",
    "        # convert start time to datetime object\n",
    "        start = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')\n",
    "        #convert end time to datetime object\n",
    "        if end_time: #if end time is provided\n",
    "            end = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')\n",
    "        else: #default 1 day after start\n",
    "            end = start + timedelta(days=1)\n",
    "\n",
    "\n",
    "        ###extract history routing table\n",
    "        history_rib = defaultdict(dict)\n",
    "        target_IP_prefix = set([])\n",
    "        for collector in tqdm(self.collector_list):\n",
    "            #rcc collects rib every 8 hours, we pick the 2nd last checkpoint\n",
    "            stream = pybgpstream.BGPStream(\n",
    "                from_time=str(start-timedelta(hours=16)), until_time=str(start-timedelta(hours=8)),\n",
    "                collectors=[collector],\n",
    "                record_type=\"ribs\",\n",
    "                filter = f'aspath \"{target_AS}$\"' #collect all as path to target_AS\n",
    "            )\n",
    "            as_path = defaultdict(dict)\n",
    "\n",
    "            for rec in tqdm(stream.records()):\n",
    "                for ele in rec:\n",
    "                    # Get the peer ASn\n",
    "                    peer = str(ele.peer_asn)\n",
    "                    hops = [k for k, g in groupby(ele.fields['as-path'].split(\" \"))]\n",
    "                    #print(ele)\n",
    "                    if str(ele.type) == \"R\":\n",
    "                        if 'as-path' and \"prefix\" in ele.fields:\n",
    "                            IP = ele.fields[\"prefix\"]\n",
    "                            target_IP_prefix.add(IP)\n",
    "                            as_path[IP][peer] = hops\n",
    "            history_rib[collector] = as_path\n",
    "\n",
    "        ###extract AS-paths before event\n",
    "        rib_before_incident = copy.deepcopy(history_rib)\n",
    "        types = {\"A\", \"W\"}\n",
    "        #construct filter by target IP prefix\n",
    "        filter_string = f\"prefix any\"\n",
    "        for ip_p in target_IP_prefix:\n",
    "            filter_string += f\" {ip_p}\" \n",
    "        for collector in tqdm(self.collector_list):\n",
    "            stream1 = pybgpstream.BGPStream(\n",
    "                from_time=str(start-timedelta(hours=8)), until_time=str(start-timedelta(minutes=10)),\n",
    "                collectors=[collector],\n",
    "                record_type=\"updates\",\n",
    "                filter = filter_string\n",
    "            )\n",
    "            \n",
    "            for rec in tqdm(stream1.records()):\n",
    "                for elem in rec:\n",
    "                    if (str(elem.type) in types) and \"prefix\" in elem.fields:\n",
    "                        IP = str(elem.fields[\"prefix\"])\n",
    "                        if str(elem.type) == \"A\" and \"as-path\" in elem.fields:\n",
    "                            peer = str(elem.peer_asn)\n",
    "                            hops = [k for k, g in groupby(elem.fields['as-path'].split(\" \"))]\n",
    "                            rib_before_incident[collector][IP][peer] = hops\n",
    "                            \n",
    "                        if str(elem.type) == \"W\":\n",
    "                            peer = str(elem.peer_asn)\n",
    "                            rib_before_incident[collector][IP][peer] = []\n",
    "\n",
    "        ###extract AS-paths after event\n",
    "        rib_after_incident = copy.deepcopy(rib_before_incident)\n",
    "        #collect information until 1min before event end or 10min after event start\n",
    "        until = min(end-timedelta(minutes=1), start+timedelta(minutes=10))\n",
    "        for collector in tqdm(self.collector_list):\n",
    "            stream1 = pybgpstream.BGPStream(\n",
    "                from_time=str(start-timedelta(minutes=10)), until_time=str(until),\n",
    "                collectors=[collector],\n",
    "                record_type=\"updates\",\n",
    "                filter = filter_string\n",
    "            )\n",
    "            \n",
    "            for rec in tqdm(stream1.records()):\n",
    "                for elem in rec:\n",
    "                    if (str(elem.type) in types) and \"prefix\" in elem.fields:\n",
    "                        IP = str(elem.fields[\"prefix\"])\n",
    "                        if str(elem.type) == \"A\" and \"as-path\" in elem.fields:\n",
    "                            peer = str(elem.peer_asn)\n",
    "                            hops = [k for k, g in groupby(elem.fields['as-path'].split(\" \"))]\n",
    "                            rib_after_incident[collector][IP][peer] = hops\n",
    "                            \n",
    "                        if str(elem.type) == \"W\":\n",
    "                            peer = str(elem.peer_asn)\n",
    "                            rib_after_incident[collector][IP][peer] = []\n",
    "\n",
    "        return history_rib, rib_before_incident, rib_after_incident\n",
    "\n",
    "    def generate_report(self, history_rib, rib_before_incident, rib_after_incident, time, IP=\"unknown\", AS=\"unkonwn\", Event_Type = \"unknown\"):\n",
    "        '''\n",
    "        provide history routing table, routing table before event, routing table after event, event time, IP or AS (must provide one)\n",
    "        generate LLM explaination and report\n",
    "        '''\n",
    "        Example_1 = \"\"\n",
    "        if IP != \"unknown\":\n",
    "            \n",
    "            event_type_list = []\n",
    "            description_list = []\n",
    "            for i in trange(5):\n",
    "                system_prompt = \"You are an expert in Border Gateway Protocol. Given a set of AS paths to a specific IP prefix, \\\n",
    "                                    describe the changes in these paths before and after a time stamp. Try to answer the following questions:\\n \\\n",
    "                                    Does the existing path from each peer to the target IP prefix change?\\\n",
    "                                    If it does, does the last AS (destination) change or not?\\n \\\n",
    "                                    Is there any new AS path to a new sub-prefix introduced?\\\n",
    "                                    If there is, compare it to the existing path with the same peer, is there any difference? Does the last \\\n",
    "                                    AS (destination) change ot not?\"\n",
    "                user_prompt = f\"{IP} is the target IP prefix. {time} is the time stamp. \\n\\\n",
    "                                Here are the paths to this IP prefix and its sub-prefixes in history: {history_rib} \\n \\\n",
    "                                Here are the paths to this IP prefix and its sub-prefixes before the time stamp: {rib_before_incident}. \\n \\\n",
    "                                Here are the paths after the time stamp: {rib_after_incident}. \\n \\\n",
    "                                All pathes are stored in a dictironary in a form of \\\n",
    "                                {{collector name: {{IP prefix: {{peer: [AS path from peer to the origin AS of IP prefix]}}}}}}. \\\n",
    "                                For example, in an AS path '97600:[97600, 12334, 54323, 2134]' 2134 is last and the destination AS.\\\n",
    "                                Now, describe the AS path changes.\"\n",
    "                message = [{\"role\":\"system\", \"content\":system_prompt}] + \\\n",
    "                            [{\"role\":\"user\", \"content\":user_prompt}]\n",
    "                output_description = self.chat(messages=message, model=self.model)[0]\n",
    "    \n",
    "                #Event type\n",
    "                system_prompt_3 = \"A BGP route leak often results in adding unexpected transit ASes without changing the \\\n",
    "                                    destination AS. In contrast, a BGP hijack typically leads to changing the destination AS in the AS path\\\n",
    "                                    and potentially redirecting traffic away from the legitimate owner. These consequence may reflect \\\n",
    "                                    in even just one AS path and in a sub-prefix.\\n \\\n",
    "                                    Now I will provide you an analysis of AS path change before and after an event, you need to identify the\\\n",
    "                                    type of this event. Think step by step. Reply in one sentence.\\n\"\n",
    "                user_prompt_3 = f\"Analysis:{output_description}\"\n",
    "                message = [{\"role\":\"system\", \"content\":system_prompt_3}] + \\\n",
    "                    [{\"role\":\"user\", \"content\":user_prompt_3}]\n",
    "                output_event_type = self.chat(messages=message, model=self.model)[0]\n",
    "                event_type_list.append(output_event_type)\n",
    "                description_list.append(output_description)\n",
    "                \n",
    "            system_prompt_00 = f\"Given a list of descriptions of the event type of the same event, identify the event type by choose the \\\n",
    "                                one in most descriptions. Output the event type and one sentence of explaination.\"\n",
    "            user_prompt_00 = f\"List of event type description {event_type_list}.\"\n",
    "            message = [{\"role\":\"system\", \"content\":system_prompt_00}] + \\\n",
    "                    [{\"role\":\"user\", \"content\":user_prompt_00}]\n",
    "            output_event = self.chat(messages=message, model=self.model)[0]\n",
    "\n",
    "            system_prompt_01 = f\"Given a list of report of the AS path changes, generate one output report that is in accordance to the most\\\n",
    "                                report in the given list.\"\n",
    "            user_prompt_01 = f\"List of AS path change report {description_list}.\"\n",
    "            message = [{\"role\":\"system\", \"content\":system_prompt_01}] + \\\n",
    "                    [{\"role\":\"user\", \"content\":user_prompt_01}]\n",
    "            output_change = self.chat(messages=message, model=self.model)[0]\n",
    "\n",
    "            #Write report\n",
    "            system_prompt_4 = \"You are an expert in BGP network anomaly detection and explaination.\\\n",
    "                                Now I detect there is an anomaly event that happened at a certain time, \\\n",
    "                                but I don't know what happened exactly and need your help.\\\n",
    "                                I will provide you an analysis of the type of the event and a description of the change in AS paths\\\n",
    "                                before and after the event. I will also provide you the AS pathes collected by many collectors to the\\\n",
    "                                target IP prefix and its sub-prefixes before the anomaly event, after the anomaly event, \\\n",
    "                                and in the history for reference. Then you need to gather these information and write a report about \\\n",
    "                                this event, including time, anomaly type, related AS number and IP address to explain in detail about \\\n",
    "                                this event. If the data provided is not enough for you to identify\\\n",
    "                                the anomaly event, based on history data, list what necessary data is missing.\"\n",
    "            user_prompt_4 = f\"{IP} is the IP prefix we detected has a problem. {time} is the time that we detected the event start.\\\n",
    "                            {output_event} is the description about the event type. \\n \\\n",
    "                            {output_change} is the description of the change in AS paths before and after the event. \\n \\\n",
    "                            Here are the paths to this IP prefix in history: {history_rib} \\n \\\n",
    "                            Here are the paths to this IP prefix before the event: {rib_before_incident}. \\n \\\n",
    "                            Here are the paths after the event: {rib_after_incident}. \\n \\\n",
    "                            All pathes are stored in a dictironary in a form of \\\n",
    "                            {{collector name: {{IP prefix: {{peer: [AS path from peer to IP prefix]}}}}}}. \\\n",
    "                            Now, write the BGP anomaly event report.\"\n",
    "            message = [{\"role\":\"system\", \"content\":system_prompt_4}] + \\\n",
    "                        [{\"role\":\"user\", \"content\":user_prompt_4}]\n",
    "            output_report = self.chat(messages=message, model=self.model)[0]\n",
    "            output_dict = {\"raw_change\": description_list,\n",
    "                          \"raw_event\": event_type_list,\n",
    "                          \"final_change\": output_change,\n",
    "                          \"final_event\": output_event,\n",
    "                          \"report\": output_report}\n",
    "            \n",
    "            \n",
    "        elif AS != \"unknown\":\n",
    "            #IP prefix not available but AS number is available\n",
    "            system_prompt = \"You are an expert in BGP network anomaly detection and explaination.\\\n",
    "                            Now we detect there is an anomaly event that happened at a certain time, \\\n",
    "                            but we don't know what happened exactly and need your help. \\\n",
    "                            We will provide you the AS pathes collected by many collectors to the IP prefixes of a target AS\\\n",
    "                            before the anomaly event and after. We will also provide AS pathes to those IP prefixes in the history. \\\n",
    "                            Also we will provide you the time. You need to explain what happened and what kind of anomaly event this is. \\\n",
    "                            Then you need to write a report about this event, including time, anomaly type, \\\n",
    "                            related AS number and IP address. If the data provided is not enough for you to write the report, please \\\n",
    "                            explain what data is missing.\"\n",
    "            user_prompt = f\"AS{AS} is the autonomous system we detected has a problem. {time} is the time that we detected the event start.\\\n",
    "                            Here are the paths to this AS in history: {history_rib} \\n \\\n",
    "                            Here are the paths to this AS before the event: {rib_before_incident}. \\n \\\n",
    "                            Here are the paths after the event: {rib_after_incident}. \\n \\\n",
    "                            All pathes are stored in a dictironary in a form of \\\n",
    "                            {{collector name: {{IP prefix: {{peer: [AS path from peer to IP prefix]}}}}}}. Now, write the report.\"\n",
    "            message = [{\"role\":\"system\", \"content\":system_prompt}] + \\\n",
    "                        [{\"role\":\"user\", \"content\":user_prompt}]\n",
    "            output_report = self.chat(messages=message, model=self.model)[0]\n",
    "        else:\n",
    "            raise(\"Must provide at least one IP or AS!\")\n",
    "        return output_report, output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d57ab9-fb7a-40ca-97ee-e4af9730964a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0522d0b47f4fb99ff72e21443c603a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21adfb4faa734fe8984e052a8860ef92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = 'Data/BGP_explain_data.csv'\n",
    "rcc_collector_lists = [\"rrc00\", \"rrc01\", \"rrc03\", \"rrc04\", \"rrc05\", \"rrc06\", \"rrc07\", \"rrc10\", \"rrc11\", \"rrc12\", \"rrc10\", \"rrc11\",\n",
    "                      \"rrc12\", \"rrc13\", \"rrc14\", \"rrc15\", \"rrc16\", \"rrc17\", \"rrc18\", \"rrc19\", \"rrc20\", \"rrc21\", \"rrc22\", \"rrc23\",\n",
    "                      \"rrc24\", \"rrc25\", \"rrc26\"]\n",
    "generator = BGP_explaination(collector_list=rcc_collector_lists, model = \"gpt-4o\", project = \"rcc\", save_path = \"e_8/\", read_path = \"e_1/\")\n",
    "generator.generate_multi_event(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8fa858-4bc8-4bec-968f-c767ae497539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
